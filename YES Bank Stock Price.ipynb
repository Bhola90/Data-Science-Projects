{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1PoyH5vSYFLU2-CSbv0Y_Rz_T6QxBZYsy","timestamp":1729741496258},{"file_id":"10B2s5af8INkHgIz_7XBjW3iNDbGY7ltx","timestamp":1721815487585}],"collapsed_sections":["vncDsAP0Gaoa","FJNUwmbgGyua","w6K7xa23Elo4","yQaldy8SH6Dl","mDgbUHAGgjLW","H0kj-8xxnORC","K5QZ13OEpz2H","lQ7QKXXCp7Bj","448CDAPjqfQr","t6dVpIINYklI","ijmpgYnKYklI","-JiQyfWJYklI","fge-S5ZAYoAp","85gYPyotYoAp","RoGjAbkUYoAp","iky9q4vBYrdO","F6T5p64dYrdO","y-Ehk30pYrdP","QHF8YVU7Yuh3","GwzvFGzlYuh3","qYpmQ266Yuh3","bbFf2-_FphqN","_ouA3fa0phqN","Seke61FWphqN","t27r6nlMphqO","r2jJGEOYphqO","b0JNsNcRphqO","jj7wYXLtphqO","eZrbJ2SmphqO","rFu4xreNphqO","gCFgpxoyphqP","OVtJsKN_phqQ","lssrdh5qphqQ","U2RJ9gkRphqQ","1M8mcRywphqQ","tgIPom80phqQ","JMzcOPDDphqR","x-EpHcCOp1ci","X_VqEhTip1ck","8zGJKyg5p1ck","PVzmfK_Ep1ck","n3dbpmDWp1ck","ylSl6qgtp1ck","ZWILFDl5p1ck","M7G43BXep1ck","Ag9LCva-p1cl","E6MkPsBcp1cl","2cELzS2fp1cl","3MPXvC8up1cl","NC_X3p0fY2L0","UV0SzAkaZNRQ","YPEH6qLeZNRQ","q29F0dvdveiT","EXh0U9oCveiU","22aHeOlLveiV","g-ATYxFrGrvw","Yfr_Vlr8HBkt","8yEUt7NnHlrM","tEA2Xm5dHt1r","I79__PHVH19G","Ou-I18pAyIpj","fF3858GYyt-u","4_0_7-oCpUZd","hwyV_J3ipUZe","3yB-zSqbpUZe","dEUvejAfpUZe","Fd15vwWVpUZf","bn_IUdTipZyH","49K5P_iCpZyH","Nff-vKELpZyI","kLW572S8pZyI","dWbDXHzopZyI","7wuGOrhz0itI","id1riN9m0vUs","578E2V7j08f6","67NQN5KX2AMe","GMQiZwjn3iu7","WVIkgGqN3qsr","XkPnILGE3zoT","Hlsf0x5436Go","mT9DMSJo4nBL","c49ITxTc407N","OeJFEK0N496M","9ExmJH0g5HBk","cJNqERVU536h","k5UmGsbsOxih","T0VqWOYE6DLQ","qBMux9mC6MCf","-oLEiFgy-5Pf","C74aWNz2AliB","2DejudWSA-a0","pEMng2IbBLp7","rAdphbQ9Bhjc","TNVZ9zx19K6k","nqoHp30x9hH9","yiiVWRdJDDil","1UUpS68QDMuG","kexQrXU-DjzY","T5CmagL3EC8N","qjKvONjwE8ra","P1XJ9OREExlT","VFOzZv6IFROw","TIqpNgepFxVj","ArJBuiUVfxKd","PiV4Ypx8fxKe","TfvqoZmBfxKf","dJ2tPlVmpsJ0","JWYfwnehpsJ1","-jK_YjpMpsJ2","HAih1iBOpsJ2","zVGeBEFhpsJ2","bmKjuQ-FpsJ3","Fze-IPXLpx6K","7AN1z2sKpx6M","9PIHJqyupx6M","_-qAgymDpx6N","Z-hykwinpx6N","h_CCil-SKHpo","cBFFvTBNJzUa","gCX9965dhzqZ","gIfDvo9L0UH2"],"cell_execution_strategy":"setup"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Project Name**    - Yes Bank Stock Closing Price Prediction\n","\n"],"metadata":{"id":"vncDsAP0Gaoa"}},{"cell_type":"markdown","source":["##### **Project Type**    - Linear Regression ML\n","##### **Contribution**    - Individual\n"],"metadata":{"id":"beRrZCGUAJYm"}},{"cell_type":"markdown","source":["# **Project Summary -**"],"metadata":{"id":"FJNUwmbgGyua"}},{"cell_type":"markdown","source":["This project aims to build a predictive model for Yes Bank's stock closing prices using historical data, machine learning, and statistical techniques. Stock price prediction is inherently complex due to the influence of numerous factors, such as market trends, economic indicators, and news events. By analyzing patterns in Yes Bank’s past stock prices, the project seeks to deliver a model that can make informed predictions about future prices. This prediction model could aid investors, traders, and financial analysts in making data-driven decisions and understanding stock behavior."],"metadata":{"id":"F6v_1wHtG2nS"}},{"cell_type":"markdown","source":["# **GitHub Link -**"],"metadata":{"id":"w6K7xa23Elo4"}},{"cell_type":"markdown","source":["Provide your GitHub Link here."],"metadata":{"id":"h1o69JH3Eqqn"}},{"cell_type":"markdown","source":["# **Problem Statement**\n"],"metadata":{"id":"yQaldy8SH6Dl"}},{"cell_type":"markdown","source":["The objective of this project is to accurately predict the closing price of Yes Bank's stock for future trading days based on historical price data. Stock prices are highly volatile, affected by a combination of financial, social, and economic factors. Traditional models often fall short of accounting for these fluctuations, especially in the short term. Thus, the primary challenge is to develop a robust model capable of providing reliable stock price predictions for Yes Bank by leveraging time series forecasting, machine learning algorithms, or a hybrid approach."],"metadata":{"id":"DpeJGUA3kjGy"}},{"cell_type":"markdown","source":["# **General Guidelines** : -  "],"metadata":{"id":"mDgbUHAGgjLW"}},{"cell_type":"markdown","source":["1.   Well-structured, formatted, and commented code is required.\n","2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n","     \n","     The additional credits will have advantages over other students during Star Student selection.\n","       \n","             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n","                       without a single error logged. ]\n","\n","3.   Each and every logic should have proper comments.\n","4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n","        \n","\n","```\n","# Chart visualization code\n","```\n","            \n","\n","*   Why did you pick the specific chart?\n","*   What is/are the insight(s) found from the chart?\n","* Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n","5. You have to create at least 15 logical & meaningful charts having important insights.\n","\n","\n","[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n","\n","U - Univariate Analysis,\n","\n","B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n","\n","M - Multivariate Analysis\n"," ]\n","\n","\n","\n","\n","\n","6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n","\n","\n","*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n","\n","\n","*   Cross- Validation & Hyperparameter Tuning\n","\n","*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n","\n","*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"ZrxVaUj-hHfC"}},{"cell_type":"markdown","source":["# ***Let's Begin !***"],"metadata":{"id":"O_i_v8NEhb9l"}},{"cell_type":"markdown","source":["## ***1. Know Your Data***"],"metadata":{"id":"HhfV-JJviCcP"}},{"cell_type":"markdown","source":["### Import Libraries"],"metadata":{"id":"Y3lxredqlCYt"}},{"cell_type":"code","source":["# Import Libraries\n","import numpy as np\n","import pandas as pd\n","from datetime import datetime\n","from datetime import timedelta\n","from datetime import date\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","from sklearn.linear_model import Lasso, Ridge\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n","import math\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.ensemble import VotingRegressor\n","from xgboost import XGBRegressor\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import PolynomialFeatures"],"metadata":{"id":"M8Vqi-pPk-HR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Loading"],"metadata":{"id":"3RnN4peoiCZX"}},{"cell_type":"code","source":["# Connecting google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"W8T239i0pMeq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Dataset\n","df = pd.read_csv('/content/drive/MyDrive/Datasets/Copy of data_YesBank_StockPrices.csv')"],"metadata":{"id":"4CkvbW_SlZ_R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset First View"],"metadata":{"id":"x71ZqKXriCWQ"}},{"cell_type":"code","source":["# Dataset First Look\n","df.head()"],"metadata":{"id":"LWNFOSvLl09H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Rows & Columns count"],"metadata":{"id":"7hBIi_osiCS2"}},{"cell_type":"code","source":["# Dataset Rows & Columns count\n","df.shape"],"metadata":{"id":"Kllu7SJgmLij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Information"],"metadata":{"id":"JlHwYmJAmNHm"}},{"cell_type":"code","source":["# Dataset Info\n","df.info()"],"metadata":{"id":"e9hRXRi6meOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Duplicate Values"],"metadata":{"id":"35m5QtbWiB9F"}},{"cell_type":"code","source":["# Dataset Duplicate Value Count\n","len(df[df.duplicated()])"],"metadata":{"id":"1sLdpKYkmox0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Missing Values/Null Values"],"metadata":{"id":"PoPl-ycgm1ru"}},{"cell_type":"code","source":["# Missing Values/Null Values Count\n","print(df.isnull().sum())"],"metadata":{"id":"GgHWkxvamxVg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What did you know about your dataset?"],"metadata":{"id":"H0kj-8xxnORC"}},{"cell_type":"markdown","source":["Answer Here"],"metadata":{"id":"gfoNAAC-nUe_"}},{"cell_type":"markdown","source":["## ***2. Understanding Your Variables***"],"metadata":{"id":"nA9Y7ga8ng1Z"}},{"cell_type":"code","source":["# Dataset Columns\n","df.columns"],"metadata":{"id":"j7xfkqrt5Ag5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset Describe\n","df.describe()"],"metadata":{"id":"DnOaZdaE5Q5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Variables Description"],"metadata":{"id":"PBTbrJXOngz2"}},{"cell_type":"markdown","source":["**Date:** month and year given\n","\n","**Open:** opening price of the stock\n","\n","**High:** highest price of the stock\n","\n","**Low:** lowest price of the stock\n","\n","**Close:** closing price of the stock"],"metadata":{"id":"aJV4KIxSnxay"}},{"cell_type":"markdown","source":["### Check Unique Values for each variable."],"metadata":{"id":"u3PMJOP6ngxN"}},{"cell_type":"code","source":["# Check Unique Values for each variable.\n","df.columns.value_counts()"],"metadata":{"id":"zms12Yq5n-jE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. ***Data Wrangling***"],"metadata":{"id":"dauF4eBmngu3"}},{"cell_type":"markdown","source":["### Data Wrangling Code"],"metadata":{"id":"bKJF3rekwFvQ"}},{"cell_type":"code","source":["# Convert object format to datetime\n","df['Date'] = pd.to_datetime(df['Date'], format='%b-%y')\n"],"metadata":{"id":"wk-9a2fpoLcV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract the month and year from date\n","df['Month'] = df['Date'].dt.strftime('%b')\n","df['Year'] = df['Date'].dt.year\n"],"metadata":{"id":"a9ppUzNrNRys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert month abbreviation to month number using datetime\n","df['Month_Num'] = pd.to_datetime(df['Month'], format='%b').dt.month"],"metadata":{"id":"fhMaWN86sN25"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Drop Columns\n","df.drop(['Month'],axis=1,inplace=True)\n","df.drop(['Date'],axis=1,inplace=True)"],"metadata":{"id":"aglV_B93wQWc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Add New Cloumn ROI(%)\n","df['ROI(%)'] = ((df['Close'] - df['Open']) / df['Open']) * 100"],"metadata":{"id":"qBZB-3kxxjDd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What all manipulations have you done and insights you found?"],"metadata":{"id":"MSa1f5Uengrz"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"LbyXE7I1olp8"}},{"cell_type":"code","source":["Avg_open_price = pd.DataFrame(df.groupby('Month_Num')['Open'].mean())\n","Avg_open_price"],"metadata":{"id":"jC6vfbPWRVmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Avg_open_price_year = pd.DataFrame(df.groupby('Year')['Open'].mean())\n","Avg_open_price_year"],"metadata":{"id":"DadGPHmHZPSI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Avg_high_price = pd.DataFrame(df.groupby('Month_Num')['High'].mean())\n","Avg_high_price"],"metadata":{"id":"zBbU_04-RVVI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Avg_low_price = pd.DataFrame(df.groupby('Month_Num')['Low'].mean())\n","Avg_low_price"],"metadata":{"id":"QKzoJDxKRVK5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Avg_close_price = pd.DataFrame(df.groupby('Month_Num')['Close'].mean())\n","Avg_close_price"],"metadata":{"id":"EYN85dIiRUzo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ROI_yearly = pd.DataFrame(df.groupby('Year')['ROI(%)'].mean())\n","ROI_yearly"],"metadata":{"id":"cGMk-wStz4Ho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lowest opening price by an year\n","Lowest_open = pd.DataFrame(df.groupby('Year')['Open'].min())\n","Lowest_open"],"metadata":{"id":"3eY4NtaiXwzI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Highest opening price by an year\n","Highest_open = pd.DataFrame(df.groupby('Year')['Open'].max())\n","Highest_open"],"metadata":{"id":"4H9aiKAlbAAp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lowest closing price by an year\n","Lowest_close = pd.DataFrame(df.groupby('Year')['Close'].min())\n","Lowest_close"],"metadata":{"id":"vOMB9g-0bBlx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Highest closing price by an year\n","Highest_close = pd.DataFrame(df.groupby('Year')['Close'].max())\n","Highest_close"],"metadata":{"id":"5AiWwlFPbDKR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# In which year having the highest Opening and Lowest Closing price\n","highest_open_lowest_close = pd.DataFrame(df.groupby('Year').agg({'Open': 'max', 'Close': 'min'}))\n","highest_open_lowest_close"],"metadata":{"id":"U2XgXhISuUxZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Higher High and Lower Low Stock Price by an Year\n","High_low_price = pd.DataFrame(df.groupby('Year').agg({'High': 'max', 'Low': 'min'}))\n","High_low_price"],"metadata":{"id":"72_EcYdtjo9B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Average Open and Close Stock Price by an Year\n","average_price = pd.DataFrame(df.groupby('Year').agg({'Open': 'mean', 'Close': 'mean'}))\n","average_price"],"metadata":{"id":"rQcYSPlIoveg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Highest Open and Close Stock Price by an Year\n","highest_price = pd.DataFrame(df.groupby('Year').agg({'Open': 'max', 'Close': 'max'}))\n","highest_price"],"metadata":{"id":"yIjFQK4KqEwX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lowest Open and Close Stock Price by an Year\n","lowest_price = pd.DataFrame(df.groupby('Year').agg({'Open': 'min', 'Close': 'min'}))\n","lowest_price"],"metadata":{"id":"HI8UteMZc-6D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"],"metadata":{"id":"GF8Ens_Soomf"}},{"cell_type":"markdown","source":["As this is the Project of Stock price, so I have used mostly Line Chart for the Better Visualization and Understanding of the Graphs. And its easy to read charts or graphs when we have Large number of insights."],"metadata":{"id":"8xDZy7SYhwoD"}},{"cell_type":"markdown","source":["#### Chart - 1 Plotting the line chart"],"metadata":{"id":"0wOQAZs5pc--"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","plt.plot(highest_open_lowest_close.index, highest_open_lowest_close['Open'], marker='o', label='Highest Open', color='green')\n","plt.plot(highest_open_lowest_close.index, highest_open_lowest_close['Close'], marker='o', label='Lowest Close', color='red')\n","\n","# Adding labels and title\n","plt.xlabel('Year')\n","plt.ylabel('Stock Price')\n","plt.title('Highest Opening and Lowest Closing price by an Year')\n","plt.legend()\n","\n","# Displaying the plot\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"giCwynvxczeZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. What is/are the insight(s) found from the chart?"],"metadata":{"id":"d2y4F25Ei9lE"}},{"cell_type":"markdown","source":["Highest Open Price - 375 in 2018\n","\n","Lowest Close Price - 275 in 2017"],"metadata":{"id":"0nf2VCCZjBTL"}},{"cell_type":"markdown","source":["#### Chart - 2 Plotting the line chart"],"metadata":{"id":"JgSq_z5LdVny"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","plt.plot(High_low_price.index, High_low_price['High'], marker='o', label='Higher High', color='green')\n","plt.plot(High_low_price.index, High_low_price['Low'], marker='o', label='Lower Low', color='red')\n","\n","# Adding labels and title\n","plt.xlabel('Year')\n","plt.ylabel('Stock Price')\n","plt.title('Higher High and Lower Low Stock Price by an Year')\n","plt.legend()\n","\n","# Displaying the plot\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"2qTN5XHDcREx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. What is/are the insight(s) found from the chart?"],"metadata":{"id":"kTRbVX2MjD4q"}},{"cell_type":"markdown","source":["Higher High Price - 400 in 2018\n","\n","Lower Low Price - 225 in 2017"],"metadata":{"id":"pMLXiZ9LjESC"}},{"cell_type":"markdown","source":["#### Chart - 3 Plotting the line chart"],"metadata":{"id":"gUFAH7vLdbSJ"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","plt.plot(average_price.index, average_price['Open'], marker='o', label='Average Open', color='blue')\n","plt.plot(average_price.index, average_price['Close'], marker='o', label='Average Close', color='red')\n","\n","# Adding labels and title\n","plt.xlabel('Year')\n","plt.ylabel('Average Stock Price')\n","plt.title('Average Open and Close Stock Price by an Year')\n","plt.legend()\n","\n","# Displaying the plot\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"704tccpycYpZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. What is/are the insight(s) found from the chart?"],"metadata":{"id":"7d7opx_8jH7B"}},{"cell_type":"markdown","source":["Average Opening and Average Closing stock prices is very close in each year.\n","\n","Here,\n","\n","Highest Average Opening - 315 in 2017\n","\n","Highest Average Closing - 325 in 2017"],"metadata":{"id":"HoW3N4rBjHnt"}},{"cell_type":"markdown","source":["#### Chart - 4 Plotting the line chart"],"metadata":{"id":"vMkScfQxdggq"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","plt.plot(highest_price.index, highest_price['Open'], marker='o', label='Highest Open', color='blue')\n","plt.plot(highest_price.index, highest_price['Close'], marker='o', label='Highest Close', color='red')\n","\n","# Adding labels and title\n","plt.xlabel('Year')\n","plt.ylabel('Stock Price')\n","plt.title('Highest Open and Close Stock Price by an Year')\n","plt.legend()\n","\n","# Displaying the plot\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"m3EiL3Eoceiy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 5 Plotting the line chart"],"metadata":{"id":"DfntCdrkdsRx"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","plt.plot(lowest_price.index, lowest_price['Open'], marker='o', label='Lowest Open', color='blue')\n","plt.plot(lowest_price.index, lowest_price['Close'], marker='o', label='Lowest Close', color='red')\n","\n","# Adding labels and title\n","plt.xlabel('Year')\n","plt.ylabel('Stock Price')\n","plt.title('Lowest Open and Close Stock Price by Year')\n","plt.legend()\n","\n","# Displaying the plot\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"2n2IXwfNckdS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 6"],"metadata":{"id":"aL_hrlK0dyNC"}},{"cell_type":"code","source":["plt.figure(figsize=(8, 6))\n","Avg_open_price.plot( marker='o', color='b')\n","plt.xlabel('Month')\n","plt.ylabel('Average Opening Price')\n","plt.title('Average Opening Price Over Months')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"7v_ESjsspbW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 7"],"metadata":{"id":"KSlN3yHqYklG"}},{"cell_type":"code","source":["plt.figure(figsize=(14, 8))\n","Avg_close_price.plot( marker='o', color='b')\n","plt.xlabel('Month')\n","plt.ylabel('Average Closing Price')\n","plt.title('Average Closing Price Over Months')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"mLf6qOdhnc9m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 8"],"metadata":{"id":"EM7whBJCYoAo"}},{"cell_type":"code","source":["plt.figure(figsize=(14, 8))\n","Avg_high_price.plot( marker='o', color='g')\n","plt.xlabel('Month')\n","plt.ylabel('Average High Price')\n","plt.title('Average High Price Over Months')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"t6GMdE67YoAp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 9"],"metadata":{"id":"4Of9eVA-YrdM"}},{"cell_type":"code","source":["plt.figure(figsize=(14, 8))\n","Avg_low_price.plot( marker='o', color='r')\n","plt.xlabel('Month')\n","plt.ylabel('Average Low Price')\n","plt.title('Average Low Price Over Months')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"irlUoxc8YrdO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 10 - Correlation (Heat Map)"],"metadata":{"id":"bamQiAODYuh1"}},{"cell_type":"code","source":["dataset_corr = df[['Open', 'High', 'Low', 'Close','Month_Num', 'Year', 'ROI(%)']]"],"metadata":{"id":"TIJwrbroYuh3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12,6))\n","sns.heatmap(dataset_corr.corr(), cmap=plt.cm.CMRmap_r, annot=True)"],"metadata":{"id":"S7SR1JBpny7L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. What is/are the insight(s) found from the chart?"],"metadata":{"id":"GwzvFGzlYuh3"}},{"cell_type":"markdown","source":["My purpose is to pick this Chart beacause a correlation heatmap shows the correlation coefficients between variables in a matrix format, using colors to highlight the strength and weakness of relationships.\n","\n","**Benefits:** It quickly visualizes which variables are strongly correlated (positive or negative), making it easy to spot potential predictors and identify multicollinearity issues.\n","\n","**Uses:** Used frequently in EDA, especially for feature selection."],"metadata":{"id":"uyqkiB8YYuh3"}},{"cell_type":"markdown","source":["#### Chart - 11- Closing Price (Distribution Chart)"],"metadata":{"id":"OH-pJp9IphqM"}},{"cell_type":"code","source":["plt.figure(figsize = (7,7))\n","sns.distplot(df['Close'],color='r')"],"metadata":{"id":"kuRf4wtuphqN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"bbFf2-_FphqN"}},{"cell_type":"markdown","source":["Histograms display the frequency distribution of a single variable, helping us understand its distribution shape (e.g., normal, skewed, uniform).\n","\n","**Benefits:** They help identify the central tendency, spread, and shape of the data distribution, as well as outliers and data skewness.\n","\n","**Uses:** Ideal for univariate analysis to check the underlying distribution of a variable, informing data transformations and adjustments."],"metadata":{"id":"loh7H2nzphqN"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"_ouA3fa0phqN"}},{"cell_type":"markdown","source":["Shape = Right skewed\n","\n","Spread =  Mostly between 10 to 360 Closing price.\n","\n","Maximum density  =  between 10 to 100 Closing price"],"metadata":{"id":"VECbqPI7phqN"}},{"cell_type":"markdown","source":["#### Chart - 12- Numerical Feature Count (Bar Chart)"],"metadata":{"id":"PIIx-8_IphqN"}},{"cell_type":"code","source":["num_features = df.describe().columns\n","num_features"],"metadata":{"id":"lqAIGUfyphqO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for col in num_features:\n","  fig = plt.figure(figsize=(9,6))\n","  ax = fig.gca()\n","  feature = df[col]\n","  feature.hist(bins = 50, ax=ax)\n","  ax.axvline(feature.mean(),color='magenta', linestyle='dashed',linewidth=2)\n","  ax.axvline(feature.median(),color='cyan', linestyle='dashed',linewidth=2)\n","  ax.set_title(col)\n","plt.show()"],"metadata":{"id":"sZLFT9tLtISd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 13- Correlation (scatter plot)"],"metadata":{"id":"BZR9WyysphqO"}},{"cell_type":"code","source":["for col in num_features[1:-1]:\n","  fig = plt.figure(figsize=(9,6))\n","  ax = fig.gca()\n","  feature =(df[col])\n","  label = df['Close']\n","  correlation = feature.corr(label)\n","  plt.scatter(x=feature, y=label)\n","  plt.xlabel(col)\n","  plt.ylabel('Closing Price')\n","  ax.set_title('Close vs ' + col + '- correlation: ' + str(correlation))\n","  z = np.polyfit(df[col], df['Close'], 1)\n","  y_hat = np.poly1d(z)(df[col])\n","\n","  plt.plot(df[col], y_hat, \"r--\", lw=1)"],"metadata":{"id":"TdPTWpAVphqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 14- Pair Plot"],"metadata":{"id":"YJ55k-q6phqO"}},{"cell_type":"code","source":["sns.pairplot(df)"],"metadata":{"id":"B2aS4O1ophqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"gCFgpxoyphqP"}},{"cell_type":"markdown","source":["I picked Pair plot beacause pair plots are used to visualize relationships between multiple variables in a dataset, displaying scatter plots for each pair of features and histograms for individual features.\n","\n","**Benefits:** They’re excellent for identifying patterns, trends, and potential correlations between variables. They can also reveal clusters, distributions, and outliers.\n","\n","**Uses:** Useful in exploratory data analysis (EDA) to see how variables interact with each other and to detect any linear or non-linear relationships."],"metadata":{"id":"TVxDimi2phqP"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"OVtJsKN_phqQ"}},{"cell_type":"markdown","source":["Answer Here"],"metadata":{"id":"ngGi97qjphqQ"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"lssrdh5qphqQ"}},{"cell_type":"markdown","source":["Answer Here"],"metadata":{"id":"tBpY5ekJphqQ"}},{"cell_type":"markdown","source":["## ***5. Hypothesis Testing***"],"metadata":{"id":"g-ATYxFrGrvw"}},{"cell_type":"markdown","source":["### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."],"metadata":{"id":"Yfr_Vlr8HBkt"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"-7MS06SUHkB-"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 1"],"metadata":{"id":"8yEUt7NnHlrM"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"tEA2Xm5dHt1r"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"HI9ZP0laH0D-"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"I79__PHVH19G"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value"],"metadata":{"id":"oZrfquKtyian"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"Ou-I18pAyIpj"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"s2U0kk00ygSB"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"fF3858GYyt-u"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"HO4K0gP5y3B4"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 2"],"metadata":{"id":"4_0_7-oCpUZd"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"hwyV_J3ipUZe"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"FnpLGJ-4pUZe"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"3yB-zSqbpUZe"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value"],"metadata":{"id":"sWxdNTXNpUZe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"dEUvejAfpUZe"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"oLDrPz7HpUZf"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"Fd15vwWVpUZf"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"4xOGYyiBpUZf"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 3"],"metadata":{"id":"bn_IUdTipZyH"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"49K5P_iCpZyH"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"7gWI5rT9pZyH"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"Nff-vKELpZyI"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value"],"metadata":{"id":"s6AnJQjtpZyI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"kLW572S8pZyI"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"ytWJ8v15pZyI"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"dWbDXHzopZyI"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"M99G98V6pZyI"}},{"cell_type":"markdown","source":["## ***6. Feature Engineering & Data Pre-processing***"],"metadata":{"id":"yLjJCtPM0KBk"}},{"cell_type":"markdown","source":["### 1. Handling Missing Values"],"metadata":{"id":"xiyOF9F70UgQ"}},{"cell_type":"code","source":["# Handling Missing Values & Missing Value Imputation"],"metadata":{"id":"iRsAHk1K0fpS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### What all missing value imputation techniques have you used and why did you use those techniques?"],"metadata":{"id":"7wuGOrhz0itI"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"1ixusLtI0pqI"}},{"cell_type":"markdown","source":["### 2. Handling Outliers"],"metadata":{"id":"id1riN9m0vUs"}},{"cell_type":"code","source":["# Handling Outliers & Outlier treatments"],"metadata":{"id":"M6w2CzZf04JK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What all outlier treatment techniques have you used and why did you use those techniques?"],"metadata":{"id":"578E2V7j08f6"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"uGZz5OrT1HH-"}},{"cell_type":"markdown","source":["### 3. Categorical Encoding"],"metadata":{"id":"89xtkJwZ18nB"}},{"cell_type":"code","source":["# Encode your categorical columns"],"metadata":{"id":"21JmIYMG2hEo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### What all categorical encoding techniques have you used & why did you use those techniques?"],"metadata":{"id":"67NQN5KX2AMe"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"UDaue5h32n_G"}},{"cell_type":"markdown","source":["### 4. Textual Data Preprocessing\n","(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"],"metadata":{"id":"Iwf50b-R2tYG"}},{"cell_type":"markdown","source":["#### 1. Expand Contraction"],"metadata":{"id":"GMQiZwjn3iu7"}},{"cell_type":"code","source":["# Expand Contraction"],"metadata":{"id":"PTouz10C3oNN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Lower Casing"],"metadata":{"id":"WVIkgGqN3qsr"}},{"cell_type":"code","source":["# Lower Casing"],"metadata":{"id":"88JnJ1jN3w7j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3. Removing Punctuations"],"metadata":{"id":"XkPnILGE3zoT"}},{"cell_type":"code","source":["# Remove Punctuations"],"metadata":{"id":"vqbBqNaA33c0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 4. Removing URLs & Removing words and digits contain digits."],"metadata":{"id":"Hlsf0x5436Go"}},{"cell_type":"code","source":["# Remove URLs & Remove words and digits contain digits"],"metadata":{"id":"2sxKgKxu4Ip3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 5. Removing Stopwords & Removing White spaces"],"metadata":{"id":"mT9DMSJo4nBL"}},{"cell_type":"code","source":["# Remove Stopwords"],"metadata":{"id":"T2LSJh154s8W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove White spaces"],"metadata":{"id":"EgLJGffy4vm0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 6. Rephrase Text"],"metadata":{"id":"c49ITxTc407N"}},{"cell_type":"code","source":["# Rephrase Text"],"metadata":{"id":"foqY80Qu48N2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 7. Tokenization"],"metadata":{"id":"OeJFEK0N496M"}},{"cell_type":"code","source":["# Tokenization"],"metadata":{"id":"ijx1rUOS5CUU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 8. Text Normalization"],"metadata":{"id":"9ExmJH0g5HBk"}},{"cell_type":"code","source":["# Normalizing Text (i.e., Stemming, Lemmatization etc.)"],"metadata":{"id":"AIJ1a-Zc5PY8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which text normalization technique have you used and why?"],"metadata":{"id":"cJNqERVU536h"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"Z9jKVxE06BC1"}},{"cell_type":"markdown","source":["#### 9. Part of speech tagging"],"metadata":{"id":"k5UmGsbsOxih"}},{"cell_type":"code","source":["# POS Taging"],"metadata":{"id":"btT3ZJBAO6Ik"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10. Text Vectorization"],"metadata":{"id":"T0VqWOYE6DLQ"}},{"cell_type":"code","source":["# Vectorizing Text"],"metadata":{"id":"yBRtdhth6JDE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which text vectorization technique have you used and why?"],"metadata":{"id":"qBMux9mC6MCf"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"su2EnbCh6UKQ"}},{"cell_type":"markdown","source":["### 4. Feature Manipulation & Selection"],"metadata":{"id":"-oLEiFgy-5Pf"}},{"cell_type":"markdown","source":["#### 1. Feature Manipulation"],"metadata":{"id":"C74aWNz2AliB"}},{"cell_type":"code","source":["# Manipulate Features to minimize feature correlation and create new features"],"metadata":{"id":"h1qC4yhBApWC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Feature Selection"],"metadata":{"id":"2DejudWSA-a0"}},{"cell_type":"code","source":["# Select your features wisely to avoid overfitting"],"metadata":{"id":"YLhe8UmaBCEE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What all feature selection methods have you used  and why?"],"metadata":{"id":"pEMng2IbBLp7"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"rb2Lh6Z8BgGs"}},{"cell_type":"markdown","source":["##### Which all features you found important and why?"],"metadata":{"id":"rAdphbQ9Bhjc"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"fGgaEstsBnaf"}},{"cell_type":"markdown","source":["### 5. Data Transformation"],"metadata":{"id":"TNVZ9zx19K6k"}},{"cell_type":"markdown","source":["#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"],"metadata":{"id":"nqoHp30x9hH9"}},{"cell_type":"code","source":["# Transform Your data"],"metadata":{"id":"I6quWQ1T9rtH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6. Data Scaling"],"metadata":{"id":"rMDnDkt2B6du"}},{"cell_type":"code","source":["# Scaling your data\n","df.info()"],"metadata":{"id":"dL9LWpySC6x_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which method have you used to scale you data and why?"],"metadata":{"id":"yiiVWRdJDDil"}},{"cell_type":"markdown","source":["### 7. Dimesionality Reduction"],"metadata":{"id":"1UUpS68QDMuG"}},{"cell_type":"markdown","source":["##### Do you think that dimensionality reduction is needed? Explain Why?"],"metadata":{"id":"kexQrXU-DjzY"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"GGRlBsSGDtTQ"}},{"cell_type":"code","source":["# DImensionality Reduction (If needed)"],"metadata":{"id":"kQfvxBBHDvCa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"],"metadata":{"id":"T5CmagL3EC8N"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"ZKr75IDuEM7t"}},{"cell_type":"markdown","source":["### 8. Data Splitting"],"metadata":{"id":"BhH2vgX9EjGr"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"20rMWloWyuOF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split your data to train and test.\n","x = df.drop('Close',axis=1)\n","y = df['Close']"],"metadata":{"id":"0CTyd2UwEyNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train test split our data\n","x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)"],"metadata":{"id":"68Iqa2wry5Mt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(x_train.shape)\n","print(x_test.shape)\n","print(y_train.shape)\n","print(y_test.shape)"],"metadata":{"id":"ZQ3XOsWWyzvT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What data splitting ratio have you used and why?"],"metadata":{"id":"qjKvONjwE8ra"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"Y2lJ8cobFDb_"}},{"cell_type":"markdown","source":["### 9. Handling Imbalanced Dataset"],"metadata":{"id":"P1XJ9OREExlT"}},{"cell_type":"markdown","source":["##### Do you think the dataset is imbalanced? Explain Why."],"metadata":{"id":"VFOzZv6IFROw"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"GeKDIv7pFgcC"}},{"cell_type":"code","source":["# Handling Imbalanced Dataset (If needed)"],"metadata":{"id":"nQsRhhZLFiDs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"],"metadata":{"id":"TIqpNgepFxVj"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"qbet1HwdGDTz"}},{"cell_type":"markdown","source":["## ***7. ML Model Implementation***"],"metadata":{"id":"VfCC591jGiD4"}},{"cell_type":"code","source":["# Appending all models parameters to the corrosponding list\n","mean_absolut_error = []\n","mean_sq_error=[]\n","root_mean_sq_error=[]\n","training_score =[]\n","r2_list=[]\n","adj_r2_list=[]\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import r2_score\n","\n","\n","def score_metrix (model,X_train,X_test,Y_train,Y_test):\n","\n","  '''\n","    train the model and gives mae, mse,rmse,r2,adj r2 score of the model\n","\n","  '''\n","  #training the model\n","  model.fit(X_train,Y_train)\n","\n","  # Training Score\n","  training  = model.score(X_train,Y_train)\n","  print(\"Training score  =\", training)\n","\n","  try:\n","      # finding the best parameters of the model if any\n","    print(f\"The best parameters found out to be :{model.best_params_} \\nwhere model best score is:  {model.best_score_} \\n\")\n","  except:\n","    pass\n","\n","\n","  #predicting the Test set and evaluting the models\n","\n","  if model == LinearRegression() or model == Lasso() or model == Ridge():\n","    Y_pred = model.predict(X_test)\n","\n","    #finding mean_absolute_error\n","    MAE  = mean_absolute_error(Y_test**2,Y_pred**2)\n","    print(\"MAE :\" , MAE)\n","\n","    #finding mean_squared_error\n","    MSE  = mean_squared_error(Y_test**2,Y_pred**2)\n","    print(\"MSE :\" , MSE)\n","\n","    #finding root mean squared error\n","    RMSE = np.sqrt(MSE)\n","    print(\"RMSE :\" ,RMSE)\n","\n","    #finding the r2 score\n","\n","    r2 = r2_score(Y_test**2,Y_pred**2)\n","    print(\"R2 :\" ,r2)\n","    #finding the adjusted r2 score\n","    adj_r2=1-(1-r2_score(Y_test**2,Y_pred**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))\n","    print(\"Adjusted R2 : \",adj_r2,'\\n')\n","\n","  else:\n","    # for tree base models\n","    Y_pred = model.predict(X_test)\n","\n","    #finding mean_absolute_error\n","    MAE  = mean_absolute_error(Y_test,Y_pred)\n","    print(\"MAE :\" , MAE)\n","\n","    #finding mean_squared_error\n","    MSE  = mean_squared_error(Y_test,Y_pred)\n","    print(\"MSE :\" , MSE)\n","\n","    #finding root mean squared error\n","    RMSE = np.sqrt(MSE)\n","    print(\"RMSE :\" ,RMSE)\n","\n","    #finding the r2 score\n","\n","    r2 = r2_score(Y_test,Y_pred)\n","    print(\"R2 :\" ,r2)\n","    #finding the adjusted r2 score\n","    adj_r2=1-(1-r2_score(Y_test,Y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))\n","    print(\"Adjusted R2 : \",adj_r2,'\\n')\n","\n","\n","  # Here we appending the parameters for all models\n","  mean_absolut_error.append(MAE)\n","  mean_sq_error.append(MSE)\n","  root_mean_sq_error.append(RMSE)\n","  training_score.append(training)\n","  r2_list.append(r2)\n","  adj_r2_list.append(adj_r2)\n","\n","  print('*'*80)\n","  # print the cofficient and intercept of which model have these parameters and else we just pass them\n","  try :\n","    print(\"coefficient \\n\",model.coef_)\n","    print('\\n')\n","    print(\"Intercept  = \" ,model.intercept_)\n","  except:\n","    pass\n","  print('\\n')\n","  print('*'*20, 'ploting the graph of Actual and predicted only with 80 observation', '*'*20)\n","\n","  # ploting the graph of Actual and predicted only with 80 observation for better visualisation which model have these parameters and else we just pass them\n","  try:\n","    # ploting the line graph of actual and predicted values\n","    plt.figure(figsize=(15,7))\n","    plt.plot((Y_pred)[:80])\n","    plt.plot((np.array(Y_test)[:80]))\n","    plt.legend([\"Predicted\",\"Actual\"])\n","    plt.show()\n","  except:\n","    pass"],"metadata":{"id":"7ebyywQieS1U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ML Model - 1 - Linear Regression"],"metadata":{"id":"u3CoayPLerPE"}},{"cell_type":"code","source":["score_metrix(LinearRegression(),x_train,x_test,y_train,y_test)"],"metadata":{"id":"PnAPaJG8uG0a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"ArJBuiUVfxKd"}},{"cell_type":"markdown","source":["The linear regression model tries to find the best-fit line that minimizes the sum of squared differences between actual values and predicted values.\n","\n","**Interpretation:**\n","\n","**MSE & RMSE:** The lower these values, the better the model's predictions. Here, an average MSE of 68.86 and RMSE of 8.29 indicate good accuracy; improvements might be possible.\n","\n","**MAE:** An average MAE of 5.38 shows that predictions deviate from actual values by about 5.38 units on average.\n","\n","**R-squared:** An average R-squared of 0.9923 indicates that 99.23% of the variance in the dependent variable is explained by the model, which is generally a strong fit.\n","\n","**Adjusted R2:** An adjusted R2 which is 0.9908 close to the original R2 0.9923 indicates that prediction is likely relevant."],"metadata":{"id":"UZq5tO466tkk"}},{"cell_type":"markdown","source":["##### Which hyperparameter optimization technique have you used and why?"],"metadata":{"id":"PiV4Ypx8fxKe"}},{"cell_type":"markdown","source":["**I used Cross Validation Technique because-**\n","\n","Cross-validation is a great way to evaluate a linear regression model's performance by splitting the dataset into multiple folds.\n","\n","This process is repeated k times, with each fold serving as the validation set once, and the results are averaged to give a more reliable measure of model performance.\n","\n","It helps to ensure that model is not overfitting or underfitting."],"metadata":{"id":"6KS9ZrKO8Pwb"}},{"cell_type":"markdown","source":["###**For Model Improvement Techniques**"],"metadata":{"id":"KTqUqQlUm4ny"}},{"cell_type":"markdown","source":["####  1 - Cross Validation & Hyperparameter Tuning"],"metadata":{"id":"zj56FTf-oI-b"}},{"cell_type":"code","source":["model = LinearRegression()\n","from sklearn.model_selection import cross_val_score, KFold"],"metadata":{"id":"oP9Mv0CLn6wd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kfold = KFold(n_splits=5, shuffle=True, random_state=42)"],"metadata":{"id":"SKhg6vXInAuY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mse_scores = cross_val_score(model, x, y, cv=kfold, scoring='neg_mean_squared_error')\n","\n","# Convert negative MSE scores to positive and calculate average MSE\n","mse_scores = -mse_scores\n","mean_mse = np.mean(mse_scores)\n","std_mse = np.std(mse_scores)\n","print(\"Cross-Validation MSE Scores for each fold:\", mse_scores)\n","print(\"Average MSE:\", mean_mse)\n","print(\"Standard Deviation of MSE:\", std_mse)"],"metadata":{"id":"cRyA8u5-n4xV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**In this case:**\n","\n","The mean MSE of 46.17 suggests that, on average, the model's predictions are good by that amount in squared terms. If this value is high (predicting stock prices, it may indicate that the model is not sufficiently accurate).\n","\n","The std MSE of 17.05 indicates variability in model performance across the folds, suggesting that the model may not be robust across all data subsets, and could potentially be improved.\n","\n","Actions Based on Evaluation\n","\n","**If Mean MSE is high:** Consider adding more features, using a more complex model, or performing feature engineering.\n","\n","**If Std MSE is high:** Check for outliers or data anomalies, try regularization to reduce overfitting, or increase the dataset size for stability.\n","Overall, a good-performing model should have both a low mean MSE and a low std MSE for consistency and accuracy."],"metadata":{"id":"OaLui8CcfxKf"}},{"cell_type":"markdown","source":["###2 - Lasso with hyperparameter tuning"],"metadata":{"id":"pZ0P5WoDeJdI"}},{"cell_type":"code","source":["L1 = Lasso() #creating variable\n","parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100,0.0014]} #lasso parameters\n","lasso_cv = GridSearchCV(L1, parameters, cv=5) #using gridsearchcv and cross validate the model"],"metadata":{"id":"U5ZfpiSRu8zV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score_metrix(lasso_cv,x_train,x_test,y_train,y_test)"],"metadata":{"id":"xS6HKY4dvEvX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###3 - **Ridge with hyperparameter tuning**"],"metadata":{"id":"Fze-IPXLpx6K"}},{"cell_type":"code","source":["L2 = Ridge() #creating variable\n","parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100,0.5,1.5,1.6,1.7,1.8,1.9]} # giving parameters\n","L2_cv = GridSearchCV(L2, parameters, scoring='r2', cv=5) #using gridsearchcv and cross validate the model\n"],"metadata":{"id":"FFrSXAtrpx6M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score_metrix(L2_cv,x_train,x_test,y_train,y_test) # fit and evaluate model with score_matrix function"],"metadata":{"id":"bJ4cRf-kr6Q0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model - 2 - **XGBoost Regression**"],"metadata":{"id":"Em8qvvYJ6_CT"}},{"cell_type":"code","source":["params = {'learning_rate':[0.5,1,1.5,2],'n_estimators':[80,100,150],'max_depth':[15,20,30]}\n","xgb_grid_search= GridSearchCV(XGBRegressor(),param_grid=params,)\n","score_metrix(xgb_grid_search,x_train,x_test,y_train,y_test)"],"metadata":{"id":"UhSrcdCH6887"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Model - 3 - **KNN Regressor**"],"metadata":{"id":"BJfOKOY68MtQ"}},{"cell_type":"code","source":["knn = KNeighborsRegressor()\n","score_metrix(knn,x_train,x_test,y_train,y_test)"],"metadata":{"id":"79bRNVQ47pVK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model - 4 - **Random Forest Regressor**"],"metadata":{"id":"arxHxFFQ8KN2"}},{"cell_type":"code","source":["# parameters for Random forest\n","param_grid = {\"n_estimators\":[50,100,150],\n","              'max_depth' : [10,15,20,25,'none'],\n","              'min_samples_split': [10,50,100],\n","              'max_features' :[24,35,40,49]}"],"metadata":{"id":"aXVHrpdu7pMp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Using Grid SearchCV\n","Ranom_forest_Grid_search = GridSearchCV(RandomForestRegressor(),param_grid=param_grid,n_jobs=-1,verbose=2)\n","score_metrix(Ranom_forest_Grid_search,x_train,x_test,y_train,y_test)"],"metadata":{"id":"JQSTuwk47pBz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model - 5 - **Gradient Boosting Regressor**"],"metadata":{"id":"ULHCcOex8Djr"}},{"cell_type":"code","source":["param_grid = {'learning_rate':[0.15,0.1,0.05,0.02,0.20],\n","              'n_estimators':[100,150,200,250],\n","              'max_depth':[2,4,6,10]}\n","\n","gradient_boost_grid_search = GridSearchCV(GradientBoostingRegressor(), param_grid=param_grid, n_jobs=-1, verbose=2)\n","score_metrix(gradient_boost_grid_search,x_train,x_test,y_train,y_test)"],"metadata":{"id":"jCrB_mKS71t9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Model - 6 - **Adaboost Boost Regressor**"],"metadata":{"id":"KheW_gQS7-Av"}},{"cell_type":"code","source":["# # parameters for Ada Boost Regressor\n","param_grid = {'n_estimators': [50,100,150,200],\n","          'learning_rate':[0.5,1,1.5,2]}\n","\n","Ada_boost_grid_search = GridSearchCV(AdaBoostRegressor(),param_grid=param_grid,n_jobs=-1)\n","score_metrix(Ada_boost_grid_search,x_train,x_test,y_train,y_test)"],"metadata":{"id":"xQ2bpxmb74b7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1. Which Evaluation metrics did you consider for a positive business impact and why?"],"metadata":{"id":"5gBSjGCC-yIT"}},{"cell_type":"markdown","source":["For practical evaluation in stock price prediction, MAE and RMSE are commonly used to get daily prediction performances.\n","\n","MAE gives a clear view of an average error. It’s easier to interpret, how far our predictions are, on average, from actual prices.\n","\n","RMSE helps monitor and penalize larger errors and directly reflects the impact of prediction inaccuracies on trading outcomes."],"metadata":{"id":"Uug7CiC5A1dr"}},{"cell_type":"markdown","source":["### 2. Which ML model did you choose from the above created models as your final prediction model and why?"],"metadata":{"id":"_PhmzG0O-nnz"}},{"cell_type":"markdown","source":["After all above created Models and its Implementation, Here I choose that the best fit Model/Algorithm is Linear Regression with cross validation technique with Lasso and Ridge hyperparameter tuning because this model having good accuracy with minimum number of errors as comparison to the other Models/Algorithms Like XGBoost, KNN, Random Forest, Gradient Boosting and AdaBoost"],"metadata":{"id":"STpM26S_BKNL"}},{"cell_type":"markdown","source":["### 3. Explain the model which you have used and the feature importance using any model explainability tool?"],"metadata":{"id":"kIflV24s-sek"}},{"cell_type":"markdown","source":["In linear regression, hyperparameter optimization is typically less than in more complex models like decision trees, as linear regression has fewer hyperparameters. However, there are techniques and choices that can improve model performance, especially when using regularized versions of linear regression.\n","\n","In this case, Cross Validation with Hyperparameters (L1 and L2) is sufficient because it is a very simple task or in smaller dataset."],"metadata":{"id":"qJgTGUcjB501"}},{"cell_type":"markdown","source":["# **Conclusion**"],"metadata":{"id":"gCX9965dhzqZ"}},{"cell_type":"markdown","source":["\"In summary, this linear regression model provides a straightforward approach to predicting stock prices with good accuracy, which indicates that the model can predict stock prices within a close range to the actual values. Here, this is the best fit model because in our case we have a smaller dataset. However, given the volatility and non-linear characteristics of stock markets, this model will have limitations in highly dynamic environments. For more precise applications, we will recommend exploring more advanced, non-linear models to capture additional market complexities.\""],"metadata":{"id":"Fjb1IsQkh3yE"}},{"cell_type":"markdown","source":["### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"],"metadata":{"id":"gIfDvo9L0UH2"}}]}